{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Garbage_detection_efficientDet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dggLVarNxxvC"
      },
      "source": [
        "# 1. Install package and download source code/image.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hGL97-GXjSUw",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "#@title\n",
        "import os\n",
        "import sys\n",
        "import tensorflow.compat.v1 as tf\n",
        "\n",
        "# Download source code.\n",
        "if \"efficientdet\" not in os.getcwd():\n",
        "  !git clone --depth 1 https://github.com/google/automl\n",
        "  os.chdir('automl/efficientdet')\n",
        "  sys.path.append('.')\n",
        "  !pip install -r requirements.txt\n",
        "  !pip install -U 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'\n",
        "else:\n",
        "  !git pull"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tow-ic7H3d7i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MODEL = 'efficientdet-d2'  #@param\n",
        "\n",
        "def download(m):\n",
        "  if m not in os.listdir():\n",
        "    !wget https://storage.googleapis.com/cloud-tpu-checkpoints/efficientdet/coco/{m}.tar.gz\n",
        "    !tar zxf {m}.tar.gz\n",
        "  ckpt_path = os.path.join(os.getcwd(), m)\n",
        "  return ckpt_path\n",
        "\n",
        "# Download checkpoint.\n",
        "ckpt_path = download(MODEL)\n",
        "print('Use model in {}'.format(ckpt_path))\n",
        "\n",
        "# Prepare image and visualization settings.\n",
        "image_url =  'https://user-images.githubusercontent.com/11736571/77320690-099af300-6d37-11ea-9d86-24f14dc2d540.png'#@param\n",
        "image_name = 'img.png' #@param\n",
        "!wget {image_url} -O img.png\n",
        "import os\n",
        "img_path = os.path.join(os.getcwd(), 'img.png')\n",
        "\n",
        "min_score_thresh = 0.35  #@param\n",
        "max_boxes_to_draw = 200  #@param\n",
        "line_thickness =   2#@param\n",
        "\n",
        "import PIL\n",
        "# Get the largest of height/width and round to 128.\n",
        "image_size = max(PIL.Image.open(img_path).size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GvdjcYpUVuQ5",
        "colab_type": "text"
      },
      "source": [
        "# 2. View graph in TensorBoard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2oz3r1LUDzr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python model_inspect.py --model_name={MODEL} --logdir=logs &> /dev/null\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir logs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RW90fiMiyg4n",
        "colab_type": "text"
      },
      "source": [
        "# 3. Training EfficientDets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C98Ye0MEyuKD",
        "colab_type": "text"
      },
      "source": [
        "## 3.1 Prepare data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrDKGqnTlTy5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIrHEEHolaEq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_dir = \"tfrecord\"\n",
        "if dataset_dir not in os.getcwd():\n",
        "    !mkdir {dataset_dir}\n",
        "# !unzip /content/drive/My\\ Drive/20200722/task_garbage_detection_2-2020_07_23_13_39_54-tfrecord-1.0.zip -d ./{dataset_dir}\n",
        "!unzip /content/drive/My\\ Drive/20200730/task_garbage_det_fps_15_img_annot_322-2020_07_24_13_19_02-tfrecord-1.0.zip -d ./{dataset_dir}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKHu-3lBwTiM",
        "colab_type": "text"
      },
      "source": [
        "## 3.2 Train Pascal VOC 2012 from COCO checkpoint for the whole net."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SD59rsZJc1WW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# generating train tfrecord is large, so we skip the execution here.\n",
        "import os\n",
        "if MODEL not in os.listdir():\n",
        "  !wget https://storage.googleapis.com/cloud-tpu-checkpoints/efficientdet/coco/{MODEL}.tar.gz\n",
        "  !tar xf {MODEL}.tar.gz\n",
        "\n",
        "!rm /content/tmp -r\n",
        "!mkdir /content/tmp; mkdir /content/tmp/model_dir/\n",
        "\n",
        "file_pattern = 'default.tfrecord'\n",
        "images_per_epoch = 322\n",
        "# key option: use --ckpt rather than --backbone_ckpt.\n",
        "!python main.py --mode=train_and_eval \\\n",
        "    --training_file_pattern=tfrecord/{file_pattern} \\\n",
        "    --validation_file_pattern=tfrecord/{file_pattern} \\\n",
        "    --model_name={MODEL} \\\n",
        "    --model_dir=/content/tmp/model_dir/{MODEL}-finetune \\\n",
        "    --ckpt={MODEL} \\\n",
        "    --train_batch_size=5 \\\n",
        "    --eval_batch_size=1 --eval_samples={images_per_epoch}  \\\n",
        "    --num_examples_per_epoch={images_per_epoch}  --num_epochs=15  \\\n",
        "    --hparams=\"num_classes=5,moving_average_decay=0,autoaugment_policy=v1\" #,mixed_precision=true\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QcBGPMCXRC8q",
        "colab_type": "text"
      },
      "source": [
        "## 3.3 View tensorboard for loss and accuracy.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vrkty06SRD0k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir /content/tmp/model_dir/\n",
        "# Notably, this is just a demo with almost zero accuracy due to very limited\n",
        "# training steps, but we can see finetuning has smaller loss than training\n",
        "# from scratch at the begining."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vxm-kvfuAZne",
        "colab_type": "text"
      },
      "source": [
        "## 3.4 Inference video"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BEqtbZI49v3M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create classes.yaml\n",
        "!echo \"1: PET\" > /content/classes.yaml\n",
        "!echo \"2: plastic\" >> /content/classes.yaml\n",
        "!echo \"3: light_bulb\" >> /content/classes.yaml\n",
        "!echo \"4: paper\" >> /content/classes.yaml\n",
        "!echo \"5: cardboard\" >> /content/classes.yaml"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zt6M64IIxEFM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "video_path = '/content/drive/My\\ Drive/20200724/VID_20200722_115436_stabiilizo_annot.mp4'"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fx2Liowdu-xO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir /content/efficientdet-d0-finetune;\n",
        "!unzip /content/drive/My\\ Drive/20200730/best_weights_d0_160.zip -d /content/efficientdet-d0-finetune/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMOl5yZlnxAR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /content/automl/efficientdet/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sp9OAE70TRX0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# MODEL = 'efficientdet-d0'\n",
        "# ckpt_path = '/content/tmp/model_dir/efficientdet-d0-finetune/model.ckpt-35622'\n",
        "# ckpt_path = '/content/efficientdet-d0-finetune/backup/model.ckpt-160'\n",
        "ckpt_path = '/content/tmp/model_dir/efficientdet-d2-finetune/backup/model.ckpt-192'\n",
        "\n",
        "saved_model_dir = '/content/saved_model'\n",
        "!rm {saved_model_dir} -r\n",
        "# Step 1: export model\n",
        "!python model_inspect.py --runmode=saved_model \\\n",
        "  --model_name={MODEL} --ckpt_path={ckpt_path} \\\n",
        "  --saved_model_dir={saved_model_dir} \\\n",
        "  --min_score_thresh=0.2 \\\n",
        "  --hparams=\"num_classes=5,moving_average_decay=0\" #,label_id_mapping=/content/classes.yaml,\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0Rj0ULgpOqm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!echo {saved_model_dir}\n",
        "!cd /content/tmp/model_dir/efficientdet-d2-finetune; zip /content/best_weights_d2_192.zip ./backup/* graph.pbtxt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s17SZqCDuAJK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !cp /content/best_weights_d0_160.zip /content/drive/My\\ Drive/20200730/"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9A_qYLbOsA7F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Step 2: do inference with saved model using saved_model_video\n",
        "!python model_inspect.py --runmode=saved_model_video \\\n",
        "  --model_name={MODEL} --ckpt_path={ckpt_path} \\\n",
        "  --saved_model_dir={saved_model_dir} \\\n",
        "  --min_score_thresh=0.5 \\\n",
        "  --input_video={video_path} --output_video=/content/output2.mov \\\n",
        "  --hparams=\"image_size=1920x1080,num_classes=5,moving_average_decay=0,label_id_mapping=/content/classes.yaml,\""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}